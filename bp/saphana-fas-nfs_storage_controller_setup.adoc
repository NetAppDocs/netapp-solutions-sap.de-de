---
sidebar: sidebar 
permalink: bp/saphana-fas-nfs_storage_controller_setup.html 
keywords: storage, controller, setup, efficiency, fabricpool, disk, shelf, aggregate, configuration, hdd, nfs, nfsv3, nfsv4, sap, hana, host, systems 
summary: In diesem Abschnitt wird die Konfiguration des NetApp Storage-Systems beschrieben. Sie müssen die primäre Installation und Einrichtung gemäß den entsprechenden ONTAP Setup- und Konfigurationsleitfäden abschließen. 
---
= Einrichtung von Storage Controllern
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:saphana-fas-nfs_time_synchronization.html["Zurück: Zeitsynchronisierung."]

In diesem Abschnitt wird die Konfiguration des NetApp Storage-Systems beschrieben. Sie müssen die primäre Installation und Einrichtung gemäß den entsprechenden ONTAP Setup- und Konfigurationsleitfäden abschließen.



== Storage-Effizienz

Inline-Deduplizierung, Inline-Deduplizierung, Inline-Komprimierung und Inline-Data-Compaction werden von SAP HANA in einer SSD-Konfiguration unterstützt.

Die Aktivierung von Storage-Effizienzfunktionen in einer HDD-basierten Konfiguration wird nicht unterstützt.



== NetApp Volume- und Aggregatverschlüsselung

Die Verwendung von NetApp Volume Encryption (NVE) und NetApp Aggregate Encryption (NAE) wird bei SAP HANA unterstützt.



== Um Servicequalität bieten zu können

Mit QoS lässt sich der Storage-Durchsatz für bestimmte SAP HANA Systeme oder andere Applikationen auf einem gemeinsam genutzten Controller begrenzen. Ein Anwendungsfall wäre, den Durchsatz von Entwicklungs- und Testsystemen zu begrenzen, damit sie bei einem gemischten Setup keinen Einfluss auf die Produktionssysteme haben.

Während des Dimensionierungsprozesses sollten Sie die Performance-Anforderungen eines nicht für die Produktion verwendeten Systems ermitteln. Entwicklungs- und Testsysteme können mit niedrigeren Leistungswerten dimensioniert werden, typischerweise im Bereich von 20 % bis 50 % eines von SAP definierten Produktionssystems-KPI.

Ab ONTAP 9 wird QoS auf Storage-Volume-Ebene konfiguriert und verwendet maximale Werte für Durchsatz (MB/s) und I/O-Menge (IOPS).

Ein großer I/O-Schreibvorgang wirkt sich am stärksten auf die Performance des Storage-Systems aus. Daher sollte die QoS-Durchsatzbegrenzung auf einen Prozentsatz der entsprechenden KPI-Werte für die SAP HANA-Speicherleistung in den Daten- und Protokoll-Volumes gesetzt werden.



== NetApp FabricPool

NetApp FabricPool darf nicht für aktive primäre Filesysteme in SAP HANA Systemen verwendet werden. Dazu gehören die Dateisysteme für den Daten- und Protokollbereich sowie die `/hana/shared` File-System. Dies führt zu unvorhersehbarer Performance, insbesondere beim Start eines SAP HANA Systems.

Die Verwendung der „nur-Snapshots“ Tiering-Politik ist möglich sowie generell die Verwendung von FabricPool an einem Backup-Ziel wie einem SnapVault oder SnapMirror Ziel.


NOTE: Durch die Verwendung von FabricPool für das Tiering von Snapshot Kopien im Primärspeicher oder die Verwendung von FabricPool zu einem Backup-Ziel werden die für die Wiederherstellung und das Recovery einer Datenbank oder anderer Aufgaben benötigte Zeit, beispielsweise das Erstellen von Systemklonen oder Korrektursystemen, geändert. Nehmen Sie dies bei der Planung Ihrer gesamten Lifecycle- Management-Strategie in Betracht und prüfen Sie, ob Ihre SLAs unter Verwendung dieser Funktion weiterhin erfüllt werden.

FabricPool ist eine gute Option, um Log-Backups auf eine andere Storage Tier zu verschieben. Das Verschieben von Backups beeinträchtigt die für das Recovery einer SAP HANA Datenbank erforderliche Zeit. Daher sollte die Option „Tiering-minimum-cooling-days“ auf einen Wert gesetzt werden, der Log-Backups, die routinemäßig für die Wiederherstellung benötigt werden, auf der lokalen fast Storage Tier platziert.



== Storage-Konfiguration

In der folgenden Übersicht sind die erforderlichen Schritte zur Storage-Konfiguration zusammengefasst. Jeder Schritt wird in den nachfolgenden Abschnitten näher beschrieben. In diesem Abschnitt wird die Storage-Hardware eingerichtet und die ONTAP Software bereits installiert. Außerdem müssen bereits die Verbindungen zwischen den Storage-Ports (10 GbE oder schneller) und dem Netzwerk vorhanden sein.

. Überprüfen Sie die richtige SAS-Stack-Konfiguration, wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#disk-shelf-connection["Festplatten-Shelf-Verbindung."]
. Erstellen und Konfigurieren der erforderlichen Aggregate wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#aggregate-configuration["Konfiguration von Aggregaten"]
. Erstellen Sie eine Storage Virtual Machine (SVM) wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#storage-virtual-machine-configuration["Konfiguration von Storage Virtual Machines"]
. Erstellen Sie LIFs, wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#logical-interface-configuration["Konfiguration der logischen Schnittstelle:"]
. Erstellen Sie Volumes in den Aggregaten, wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#volume-configuration-for-sap-hana-single-host-systems["Volume-Konfiguration für SAP HANA Single-Host-Systeme"] Und link:saphana-fas-nfs_storage_controller_setup.html#volume-configuration-for-sap-hana-multiple-host-systems["Volume-Konfiguration für SAP HANA Multiple-Host-Systeme."]
. Legen Sie die erforderlichen Volume-Optionen fest, wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#volume-options["Volume-Optionen:"]
. Legen Sie die erforderlichen Optionen für NFSv3 fest, wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#nfs-configuration-for-nfsv3["NFS-Konfiguration für NFSv3"] Oder für NFSv4 wie in beschrieben link:saphana-fas-nfs_storage_controller_setup.html#nfs-configuration-for-nfsv4["NFS-Konfiguration für NFSv4:"]
. Mounten Sie die Volumes in den Namespace und legen Sie die Richtlinien für den Export wie in beschrieben fest link:saphana-fas-nfs_storage_controller_setup.html#mount-volumes-to-namespace-and-set-export-policies["Volumes werden in Namespace mounten und Richtlinien für den Export festlegen."]




== Festplatten-Shelf-Verbindung

Mit HDDs können maximal zwei DS2246 Festplatten-Shelfs oder vier DS224C Festplatten-Shelfs mit einem SAS-Stack verbunden werden, um die erforderliche Performance für die SAP HANA-Hosts zu liefern, wie in der folgenden Abbildung dargestellt. Die Festplatten in jedem Shelf müssen gleichmäßig auf beide Controller des HA-Paars verteilt werden.

image:saphana-fas-nfs_image13.png["Fehler: Fehlendes Grafikbild"]

Bei SSDs kann maximal ein Platten-Shelf mit einem SAS-Stack verbunden werden, um die erforderliche Performance für die SAP HANA-Hosts zu liefern, wie in der folgenden Abbildung dargestellt. Die Festplatten in jedem Shelf müssen gleichmäßig auf beide Controller des HA-Paars verteilt werden. Mit dem DS224C Festplatten-Shelf können auch Quad-Path-SAS-Verkabelung verwendet werden, ist aber nicht erforderlich.

image:saphana-fas-nfs_image14.png["Fehler: Fehlendes Grafikbild"]



== Konfiguration von Aggregaten

Im Allgemeinen müssen zwei Aggregate pro Controller konfiguriert werden, unabhängig vom verwendeten Festplatten-Shelf oder der Festplattentechnologie (SSD oder HDD). Für Systeme der FAS2000 Serie genügt ein Datenaggregat.



=== Aggregatkonfiguration mit HDDs

Die folgende Abbildung zeigt eine Konfiguration für acht SAP HANA-Hosts. Vier SAP HANA-Hosts sind mit jedem Storage-Controller verbunden. Zwei separate Aggregate, eines an jedem Storage Controller, sind konfiguriert. Jedes Aggregat ist mit 4 × 10 = 40 Datenfestplatten (HDDs) konfiguriert.

image:saphana-fas-nfs_image15.png["Fehler: Fehlendes Grafikbild"]



=== Aggregat-Konfiguration mit nur SDD-Systemen

Im Allgemeinen müssen zwei Aggregate pro Controller konfiguriert werden, unabhängig davon, welches Platten-Shelf oder Festplattentechnologie (SSDs oder HDDs) zum Einsatz kommt. Für Systeme der FAS2000 Serie genügt ein Datenaggregat.

Die folgende Abbildung zeigt eine Konfiguration mit 12 SAP HANA Hosts, die auf einem 12-GB-SAS-Shelf ausgeführt werden und mit ADPv2 konfiguriert sind. Sechs SAP-HANA-Hosts sind mit jedem Storage-Controller verbunden. Vier separate Aggregate, zwei an jedem Storage Controller, sind konfiguriert. Jedes Aggregat ist mit 11 Festplatten mit neun Daten und zwei Parity-Festplatten-Partitionen konfiguriert. Für jeden Controller stehen zwei Ersatzpartitionen zur Verfügung.

image:saphana-fas-nfs_image16.jpg["Fehler: Fehlendes Grafikbild"]



== Konfiguration von Storage Virtual Machines

Mehrere SAP Landschaften mit SAP HANA Datenbanken können eine einzige SVM nutzen. Darüber hinaus kann jeder SAP-Landschaft bei Bedarf eine SVM zugewiesen werden, falls diese von verschiedenen Teams innerhalb eines Unternehmens gemanagt werden.

Wenn bei der Erstellung einer neuen SVM automatisch ein QoS-Profil erstellt und zugewiesen wurde, entfernen Sie das automatisch erstellte Profil aus der SVM, um die erforderliche Performance für SAP HANA bereitzustellen:

....
vserver modify -vserver <svm-name> -qos-policy-group none
....


== Konfiguration der logischen Schnittstelle

Für SAP HANA Produktionssysteme müssen unterschiedliche LIFs zum Mounten des Daten-Volumes und des Protokoll-Volumes vom SAP HANA-Host verwendet werden. Daher sind mindestens zwei LIFs erforderlich.

Die Daten- und Protokoll-Volume-Mounts verschiedener SAP HANA Hosts können einen physischen Storage-Netzwerk-Port mithilfe derselben LIFs oder mithilfe individueller LIFs für jeden Mount gemeinsam nutzen.

Die maximale Anzahl an Daten- und Protokoll-Volume-Mounts pro physische Schnittstelle sind in der folgenden Tabelle aufgeführt.

|===
| Ethernet-Port-Geschwindigkeit | 10 GbE | 25 GbE | 40 GbE | 100 GeE 


| Maximale Anzahl an Protokoll- oder Daten-Volume-Mounts pro physischem Port | 2 | 6 | 12 | 24 
|===

NOTE: Die gemeinsame Nutzung einer logischen Schnittstelle zwischen verschiedenen SAP HANA Hosts erfordert möglicherweise eine Neuaufbindung von Daten- oder Protokoll-Volumes an eine andere logische Schnittstelle. Durch diese Änderung werden Performance-Einbußen vermieden, wenn ein Volume auf einen anderen Storage Controller verschoben wird.

Entwicklungs- und Testsysteme können mehr Daten und Volume-Mounts oder LIFs auf einer physischen Netzwerkschnittstelle verwenden.

Für Produktions-, Entwicklungs- und Testsysteme liefert `/hana/shared` Das Filesystem kann dieselbe LIF wie das Daten- oder Protokoll-Volume verwenden.



== Volume-Konfiguration für SAP HANA Single-Host-Systeme

Die folgende Abbildung zeigt die Volume-Konfiguration von vier SAP HANA-Systemen mit einem Host. Die Daten- und Protokoll-Volumes jedes SAP HANA Systems werden auf verschiedene Storage Controller verteilt. Beispiel: Volume `SID1_data_mnt00001` Wird auf Controller A und Volume konfiguriert `SID1_log_mnt00001` Ist auf Controller B konfiguriert


NOTE: Wenn für die SAP HANA Systeme nur ein Storage-Controller eines HA-Paars verwendet wird, können Daten- und Protokoll-Volumes auch auf demselben Storage Controller gespeichert werden.


NOTE: Wenn die Daten- und Protokoll-Volumes auf demselben Controller gespeichert sind, muss der Zugriff des Servers auf den Storage mit zwei unterschiedlichen LIFs durchgeführt werden: Einer logischen Schnittstelle für den Zugriff auf das Daten-Volume und einem für den Zugriff auf das Protokoll-Volume.

image:saphana-fas-nfs_image17.jpg["Fehler: Fehlendes Grafikbild"]

Für jeden SAP HANA DB-Host, ein Daten-Volume, ein Protokoll-Volume und ein Volume für `/hana/shared` Werden konfiguriert. Die folgende Tabelle zeigt eine Beispielkonfiguration für SAP HANA-Systeme mit einem Host.

|===
| Zweck | Aggregat 1 bei Controller A | Aggregat 2 bei Controller A | Aggregat 1 bei Controller B | Aggregat 2 bei Controller b 


| Daten-, Protokoll- und freigegebene Volumes für System SID1 | Datenvolumen: SID1_Data_mnt00001 | Freigegebenes Volume: SID1_Shared | – | Protokollvolumen: SID1_log_mnt00001 


| Daten-, Protokoll- und freigegebene Volumes für System SID2 | – | Protokollvolumen: SID2_log_mnt00001 | Datenvolumen: SID2_Data_mnt00001 | Freigegebenes Volume: SID2_Shared 


| Daten-, Protokoll- und gemeinsam genutzte Volumes für System SID3 | Gemeinsam genutztes Volume: SID3_shared | Datenvolumen: SID3_Data_mnt00001 | Protokollvolumen: SID3_log_mnt00001 | – 


| Daten-, Protokoll- und gemeinsam genutzte Volumes für System SID4 | Protokollvolumen: SID4_log_mnt00001 | – | Gemeinsam genutztes Volume: SID4_shared | Datenvolumen: SID4_Data_mnt00001 
|===
Die folgende Tabelle zeigt ein Beispiel für die Mount-Point-Konfiguration für ein System mit einem einzelnen Host. Um das Home-Verzeichnis des zu platzieren `sidadm` Benutzer auf dem zentralen Speicher, der `/usr/sap/SID` Dateisystem sollte vom gemountet werden `SID_shared` Datenmenge:

|===
| Verbindungspfad | Verzeichnis | Bereitstellungspunkt beim HANA-Host 


| SID_Data_mnt00001 | – | /hana/Data/SID/mnt00001 


| SID_Log_mnt00001 | – | /hana/log/SID/mnt00001 


| SID_freigegeben | Usr-sap freigegeben | /Usr/sap/SID /hana/Shared 
|===


== Volume-Konfiguration für SAP HANA Multiple-Host-Systeme

Die folgende Abbildung zeigt die Volume-Konfiguration eines 4+1 SAP HANA-Systems. Die Daten- und Protokoll-Volumes jedes SAP HANA-Hosts werden auf verschiedene Storage-Controller verteilt. Beispiel: Volume `SID1_data1_mnt00001` Wird auf Controller A und Volume konfiguriert `SID1_log1_mnt00001` Ist auf Controller B konfiguriert


NOTE: Wenn für das SAP HANA System nur ein Storage-Controller eines HA-Paars verwendet wird, können die Daten- und Protokoll-Volumes auch auf demselben Storage Controller gespeichert werden.


NOTE: Wenn die Daten- und Protokoll-Volumes auf demselben Controller gespeichert sind, muss der Zugriff des Servers auf den Storage mit zwei verschiedenen LIFs durchgeführt werden: Einem für den Zugriff auf das Daten-Volume und einem für den Zugriff auf das Protokoll-Volume.

image:saphana-fas-nfs_image18.jpg["Fehler: Fehlendes Grafikbild"]

Für jeden SAP HANA-Host werden ein Daten-Volume und ein Protokoll-Volume erstellt. Der `/hana/shared` Das Volume wird von allen Hosts des SAP HANA-Systems verwendet. Die folgende Tabelle zeigt eine Beispielkonfiguration für ein SAP HANA-System mit mehreren Hosts und vier aktiven Hosts.

|===
| Zweck | Aggregat 1 bei Controller A | Aggregat 2 bei Controller A | Aggregat 1 bei Controller B | Aggregieren 2 bei Controller B 


| Daten- und Protokoll-Volumes für Node 1 | Datenvolumen: SID_Data_mnt00001 | – | Protokollvolumen: SID_log_mnt00001 | – 


| Daten- und Protokoll-Volumes für Node 2 | Protokollvolumen: SID_log_mnt002 | – | Datenvolumen: SID_Data_mnt002 | – 


| Daten- und Protokoll-Volumes für Node 3 | – | Datenvolumen: SID_Data_mnt00003 | – | Protokollvolumen: SID_log_mnt00003 


| Daten- und Protokoll-Volumes für Node 4 | – | Protokollvolumen: SID_log_mnt004 | – | Datenvolumen: SID_Data_mnt00004 


| Gemeinsames Volume für alle Hosts | Gemeinsam genutztes Volume: SID_shared | – | – | – 
|===
Die folgende Tabelle zeigt die Konfiguration und die Bereitstellungspunkte eines Systems mit mehreren Hosts mit vier aktiven SAP HANA Hosts. Um die Home-Verzeichnisse des zu platzieren `sidadm` Benutzer jedes Hosts im zentralen Speicher, der `/usr/sap/SID` Dateisysteme werden über eingebunden `SID_shared` Datenmenge:

|===
| Verbindungspfad | Verzeichnis | Bereitstellungspunkt beim SAP HANA-Host | Hinweis 


| SID_Data_mnt00001 | – | /hana/Data/SID/mnt00001 | Auf allen Hosts montiert 


| SID_Log_mnt00001 | – | /hana/log/SID/mnt00001 | Auf allen Hosts montiert 


| SID_Data_mnt00002 | – | /hana/Data/SID/mnt002 | Auf allen Hosts montiert 


| SID_Log_mnt00002 | – | /hana/log/SID/mnt002 | Auf allen Hosts montiert 


| SID_Data_mnt00003 | – | /hana/Data/SID/mnt003 | Auf allen Hosts montiert 


| SID_log_mnt00003 | – | /hana/log/SID/mnt003 | Auf allen Hosts montiert 


| SID_Data_mnt00004 | – | /hana/Data/SID/mnt004 | Auf allen Hosts montiert 


| SID_log_mnt00004 | – | /hana/log/SID/mnt004 | Auf allen Hosts montiert 


| SID_freigegeben | Freigegeben | /hana/Shared/ | Auf allen Hosts montiert 


| SID_freigegeben | Usr-sap-host1 | /Usr/sap/SID | Angehängt auf Host 1 


| SID_freigegeben | Usr-sap-host2 | /Usr/sap/SID | Angehängt auf Host 2 


| SID_freigegeben | Usr-sap-host3 | /Usr/sap/SID | Angehängt auf Host 3 


| SID_freigegeben | Usr-sap-host4 | /Usr/sap/SID | Angehängt auf Host 4 


| SID_freigegeben | Usr-sap-host5 | /Usr/sap/SID | Angehängt auf Host 5 
|===


== Volume-Optionen

Sie müssen die in der folgenden Tabelle aufgeführten Volume-Optionen auf allen SVMs überprüfen und festlegen. Bei einigen Befehlen müssen Sie in den erweiterten Berechtigungsebene in ONTAP wechseln.

|===
| Aktion | Befehl 


| Deaktivieren Sie die Sichtbarkeit des Snapshot Verzeichnisses | vol modify -vserver <vserver-Name> -Volume <volname> -Snapdir-Access false 


| Deaktivieren Sie automatische Snapshot Kopien | vol modify –vserver <vserver-Name> -Volume <volname> -Snapshot-Policy keine 


| Deaktivieren Sie Updates der Zugriffszeit außer dem SID_Shared Volume  a| 
Setzen Sie Advanced vol modify -vserver <vserver-Name> -Volume <volname> -atime-Update false Administrator

|===


== NFS-Konfiguration für NFSv3

Die in der folgenden Tabelle aufgeführten NFS-Optionen müssen verifiziert und auf allen Storage Controllern eingestellt werden.

Für einige der angezeigten Befehle müssen Sie in den erweiterten Berechtigungsebene in ONTAP wechseln.

|===
| Aktion | Befehl 


| Aktivieren Sie NFSv3 | nfs modify -vserver <vserver-Name> v3.0 aktiviert 


| ONTAP 9: Legen Sie die maximale Übertragungsgröße für NFS TCP auf 1 MB fest  a| 
Erweitertes nfs modify -vserver <vserver_Name> -tcp-max-xfer-size 1048576 set admin



| ONTAP 8: Legen Sie die Lese- und Schreibgröße für NFS auf 64 KB fest  a| 
Erweitertes nfs modify -vserver <vserver-Name> -v3-tcp-max-read-size 65536 nfs modify -vserver <vserver-Name> -v3-tcp-max-write-size 65536 set admin

|===


== NFS-Konfiguration für NFSv4

Die in der folgenden Tabelle aufgeführten NFS-Optionen müssen verifiziert und auf allen SVMs eingestellt werden.

Bei einigen Befehlen müssen Sie in den erweiterten Berechtigungsebene in ONTAP wechseln.

|===
| Aktion | Befehl 


| Aktivieren Sie NFSv4 | nfs modify -vserver <vserver-Name> -v4.1 aktiviert 


| ONTAP 9: Legen Sie die maximale Übertragungsgröße für NFS TCP auf 1 MB fest | Erweitertes nfs modify -vserver <vserver_Name> -tcp-max-xfer-size 1048576 set admin 


| ONTAP 8: Legen Sie die Lese- und Schreibgröße für NFS auf 64 KB fest | Erweitertes nfs modify -vserver <vserver_Name> -tcp-max-xfer-size 65536 set admin 


| NFSv4-Zugriffssteuerungslisten (ACLs) deaktivieren | nfs modify -vserver <vServer_Name> -v4.1-acl deaktiviert 


| Legen Sie die NFSv4-Domain-ID fest | nfs modify -vServer <vServer_Name> -v4-id-Domain <Domain-Name> 


| Deaktivieren der NFSv4-Lesedelegierung | nfs modify -vServer <vServer_Name> -v4.1-read-Delegation deaktiviert 


| Deaktivieren der NFSv4-Schreibdelegation | nfs modify -vServer <vServer_Name> -v4.1-write-Delegation deaktiviert 


| Deaktivieren Sie die numerischen nfsv4-ids | nfs modify -vServer <vServer_Name> -v4-numeric-ids deaktiviert 
|===

NOTE: Bitte beachten Sie, dass zur Deaktivierung von Nummerierung-ids eine Benutzerverwaltung erforderlich ist, wie unter beschrieben link:saphana-fas-nfs_sap_hana_installation_preparations_for_nfsv4.html["Vorbereitung der Installation von SAP HANA auf NFSv4:"]


NOTE: Die NFSv4-Domänen-ID muss auf allen Linux Servern auf denselben Wert festgelegt sein (/`etc/idmapd.conf`) Und SVMs, wie in beschrieben link:saphana-fas-nfs_sap_hana_installation_preparations_for_nfsv4.html["Vorbereitung der Installation von SAP HANA auf NFSv4:"]


NOTE: Wenn Sie NFSV4.1 verwenden, kann pNFS aktiviert und verwendet werden.

Legen Sie die NFSv4-Leasing-Zeit auf der SVM fest, wie in der folgenden Tabelle gezeigt, wenn SAP HANA mehrere Host-Systeme verwendet werden.

|===
| Aktion | Befehl 


| Legen Sie die Leasing-Zeit für NFSv4 fest. | Stellen Sie den erweiterten nfs modify -vServer <vserver_Name> -v4-lease-Sekunden 10 fest: Admin 
|===
Ab HANA 2.0 SPS4 stellt HANA Parameter zur Steuerung des Failover-Verhaltens bereit. Anstatt die Leasing-Zeit auf SVM-Ebene einzustellen, empfiehlt NetApp die Verwendung dieser HANA-Parameter. Die Parameter befinden sich innerhalb `nameserver.ini` Wie in der folgenden Tabelle dargestellt. Halten Sie das Standard-Wiederholungsintervall von 10 Sekunden in diesen Abschnitten ein.

|===
| Abschnitt in nameserver.ini | Parameter | Wert 


| Failover | Normal_Wiederholungen | 9 


| Distributed_Watchdog | Deaktivierung_Wiederholungen | 11 


| Distributed_Watchdog | Takeover_Wiederholungen | 9 
|===


== Volumes werden in Namespace mounten und Richtlinien für den Export festlegen

Wenn ein Volume erstellt wird, muss das Volume im Namespace gemountet werden. In diesem Dokument gehen wir davon aus, dass der Name des Verbindungspfads dem Namen des Volumes entspricht. Standardmäßig wird das Volume mit der Standardrichtlinie exportiert. Die Exportpolitik kann bei Bedarf angepasst werden.

link:saphana-fas-nfs_host_setup.html["Weiter: Host-Einrichtung."]
