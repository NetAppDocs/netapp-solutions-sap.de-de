---
sidebar: sidebar 
permalink: bp/saphana_aff_fc_storage_sizing.html 
keywords:  
summary:  
---
= Storage-Dimensionierung
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
Der folgende Abschnitt bietet einen Überblick über die Performance- und Kapazitätsüberlegungen, die für die Dimensionierung eines Storage-Systems für SAP HANA erforderlich sind.


NOTE: Wenden Sie sich an Ihren Vertriebsmitarbeiter von NetApp oder einen NetApp Partner, um den Prozess der Storage-Größenbemessung zu unterstützen und Ihnen beim Aufbau einer optimal dimensionierten Storage-Umgebung zu helfen.



== Überlegungen zur Performance

SAP hat einen statischen Satz von Storage Key Performance-Indikatoren definiert. Diese KPIs sind für alle produktiven SAP HANA-Umgebungen gültig, unabhängig von der Speichergröße der Datenbank-Hosts und der Anwendungen, die die SAP HANA-Datenbank nutzen. Diese KPIs gelten für Single-Host-, mehrere Hosts-, Business Suite on HANA-, Business Warehouse on HANA-, S/4HANA- und BW/4HANA-Umgebungen. Daher hängt der aktuelle Ansatz zur Performance-Dimensionierung nur von der Anzahl aktiver SAP HANA-Hosts ab, die an das Storage-System angeschlossen sind.


NOTE: Storage-Performance-KPIs sind nur für SAP HANA Produktionssysteme erforderlich, können aber in allen HANA-Systemen implementiert werden.

SAP liefert ein Performance-Testtool, das zur Validierung der Storage-Systemperformance der am Storage angeschlossenen aktiven SAP HANA Hosts verwendet werden muss.

NetApp hat die maximale Anzahl an SAP HANA Hosts getestet und vordefiniert, die an ein bestimmtes Storage-Modell angeschlossen werden können, während gleichzeitig die erforderlichen Storage-KPIs von SAP für produktionsbasierte SAP HANA Systeme erfüllt werden.

Mit dem SAP Performance-Testtool wurde die maximale Anzahl an SAP HANA Hosts ermittelt, die in einem Platten-Shelf ausgeführt werden können und die Mindestanzahl der pro SAP HANA Host benötigten SSDs erforderlich ist. Dieser Test berücksichtigt nicht die tatsächlichen Storage-Kapazitätsanforderungen der Hosts. Außerdem müssen die Kapazitätsanforderungen berechnet werden, um die tatsächlich benötigte Storage-Konfiguration zu bestimmen.



=== SAS-Festplatten-Shelf

Das 12-GB-SAS-Festplatten-Shelf (DS224C) sorgt für das Performance-Sizing mit festen Festplatten-Shelf-Konfigurationen:

* Halb beladene Festplatten-Shelfs mit 12 SSDs
* Voll beladene Festplatten-Shelfs mit 24 SSDs


Beide Konfigurationen verwenden die erweiterte Laufwerkpartitionierung (Advanced Drive Partitioning, ADPv2). Ein halb beladenes Platten-Shelf unterstützt bis zu 9 SAP HANA-Hosts. Ein voll beladenes Shelf unterstützt bis zu 14 Hosts in einem einzigen Platten-Shelf. Die SAP HANA-Hosts müssen auf beide Storage Controller verteilt sein.


NOTE: Das DS224C Festplatten-Shelf muss über 12 GB SAS verbunden werden, um die Anzahl von SAP HANA Hosts zu unterstützen.

Das 6-Gbit-SAS-Platten-Shelf (DS2246) unterstützt maximal 4 SAP HANA Hosts. Die SSDs und SAP HANA-Hosts müssen auf beide Storage-Controller verteilt sein. In der folgenden Abbildung ist die unterstützte Anzahl von SAP HANA-Hosts pro Festplatten-Shelf zusammengefasst.

|===
|  | 6-Gbit-SAS-Shelfs (DS2246) mit voller Betriebslast 24 SSDs | 12-GB-SAS-Shelfs (DS224C) mit 12 SSDs und ADPv2; halber beladen | 12-GB-SAS-Shelfs (DS224C) mit 24 SSDs und ADPv2 voll beladen 


| Maximale Anzahl von SAP HANA-Hosts pro Festplatten-Shelf | 4 | 9 | 14 
|===

NOTE: Diese Berechnung erfolgt unabhängig vom eingesetzten Storage Controller. Durch das Hinzufügen weiterer Platten-Shelves wird nicht die maximale Anzahl von SAP HANA-Hosts erhöht, die ein Storage-Controller unterstützen kann.



=== NS224 NVMe-Shelf

Eine NVMe-SSD (Daten) unterstützt bis zu 5 SAP HANA-Hosts.
Die SSDs und SAP HANA-Hosts müssen auf beide Storage-Controller verteilt sein.
Gleiches gilt für die internen NVMe-Festplatten von Systemen der Serien AFF A800, AFF A70 und AFF A90.


NOTE: Durch das Hinzufügen weiterer Platten-Shelves wird nicht die maximale Anzahl von SAP HANA-Hosts erhöht, die ein Storage-Controller unterstützen kann.



== Heterogenen Workloads

SAP HANA und andere Applikations-Workloads werden auf demselben Storage Controller oder im selben Storage-Aggregat unterstützt. Es ist jedoch eine NetApp Best Practice, SAP HANA-Workloads von allen anderen Applikations-Workloads zu trennen.

SAP HANA-Workloads und andere Applikations-Workloads können entweder auf demselben Storage-Controller oder demselben Aggregat implementiert werden. Falls ja, müssen Sie sicherstellen, dass in der Umgebung mit heterogenen Workloads für SAP HANA eine ausreichende Performance verfügbar ist. NetApp empfiehlt außerdem, Parameter für Quality of Service (QoS) zu verwenden, um die Auswirkungen anderer Applikationen auf SAP HANA Applikationen zu regulieren und den Durchsatz für SAP HANA Applikationen zu garantieren.

Das SAP HCMT-Testtool muss verwendet werden, um zu prüfen, ob zusätzliche SAP HANA Hosts auf einem vorhandenen Storage Controller ausgeführt werden können, der bereits für andere Workloads verwendet wird. SAP Applikations-Server können wie die SAP HANA Datenbanken sicher auf demselben Storage Controller und/oder Aggregat platziert werden.



== Überlegungen zur Kapazität

Eine detaillierte Beschreibung der Kapazitätsanforderungen für SAP HANA ist im https://launchpad.support.sap.com/#/notes/1900823["SAP-Hinweis 1900823"^] Whitepaper:


NOTE: Das Kapazitätsdimensionieren der gesamten SAP Landschaft mit mehreren SAP HANA Systemen muss mithilfe von SAP HANA Storage-Größenanpassungs-Tools von NetApp ermittelt werden. Wenden Sie sich an NetApp oder Ihren Ansprechpartner bei NetApp Partnern, um den Prozess der Storage-Größenbemessung für eine ausreichend dimensionierte Storage-Umgebung zu validieren.



== Konfiguration des Performance-Testtool

Ab SAP HANA 1.0 SPS10 führte SAP Parameter ein, um das I/O-Verhalten anzupassen und die Datenbank für das verwendete Datei- und Speichersystem zu optimieren. Diese Parameter müssen auch für das Performance-Test-Tool von SAP eingestellt werden, wenn die Storage-Performance mit dem SAP-Testtool getestet wird.

NetApp führte Performance-Tests durch, um die optimalen Werte zu ermitteln. In der folgenden Tabelle sind die Parameter aufgeführt, die in der Konfigurationsdatei des SAP-Testwerkzeugs festgelegt werden müssen.

|===
| Parameter | Wert 


| max_parallel_io_Requests | 128 


| Async_read_Submit | Ein 


| Async_write_submit_Active | Ein 


| Async_Write_Submit_Blocks | Alle 
|===
Weitere Informationen zur Konfiguration von SAP-Testtool finden Sie unter https://service.sap.com/sap/support/notes/1943937["SAP-Hinweis 1943937"^] Für HWCCT (SAP HANA 1.0) und https://launchpad.support.sap.com/["SAP-Hinweis 2493172"^] FÜR HCMT/HCOT (SAP HANA 2.0).

Das folgende Beispiel zeigt, wie Variablen für den HCMT/HCOT-Ausführungsplan festgelegt werden können.

....
…
{
         "Comment": "Log Volume: Controls whether read requests are submitted asynchronously, default is 'on'",
         "Name": "LogAsyncReadSubmit",
         "Value": "on",
         "Request": "false"
      },
      {
         "Comment": "Data Volume: Controls whether read requests are submitted asynchronously, default is 'on'",
         "Name": "DataAsyncReadSubmit",
         "Value": "on",
         "Request": "false"
      },
      {
         "Comment": "Log Volume: Controls whether write requests can be submitted asynchronously",
         "Name": "LogAsyncWriteSubmitActive",
         "Value": "on",
         "Request": "false"
      },
      {
         "Comment": "Data Volume: Controls whether write requests can be submitted asynchronously",
         "Name": "DataAsyncWriteSubmitActive",
         "Value": "on",
         "Request": "false"
      },
      {
         "Comment": "Log Volume: Controls which blocks are written asynchronously. Only relevant if AsyncWriteSubmitActive is 'on' or 'auto' and file system is flagged as requiring asynchronous write submits",
         "Name": "LogAsyncWriteSubmitBlocks",
         "Value": "all",
         "Request": "false"
      },
      {
         "Comment": "Data Volume: Controls which blocks are written asynchronously. Only relevant if AsyncWriteSubmitActive is 'on' or 'auto' and file system is flagged as requiring asynchronous write submits",
         "Name": "DataAsyncWriteSubmitBlocks",
         "Value": "all",
         "Request": "false"
      },
      {
         "Comment": "Log Volume: Maximum number of parallel I/O requests per completion queue",
         "Name": "LogExtMaxParallelIoRequests",
         "Value": "128",
         "Request": "false"
      },
      {
         "Comment": "Data Volume: Maximum number of parallel I/O requests per completion queue",
         "Name": "DataExtMaxParallelIoRequests",
         "Value": "128",
         "Request": "false"
      }, …
....
Diese Variablen müssen für die Testkonfiguration verwendet werden. Dies ist in der Regel bei den vordefinierten Testsuiten der Fall, die SAP mit dem HCMT/HCOT-Tool liefert. Das folgende Beispiel für einen 4k-Protokollschreibtest stammt aus einer Testsuite.

....
…
      {
         "ID": "D664D001-933D-41DE-A904F304AEB67906",
         "Note": "File System Write Test",
         "ExecutionVariants": [
            {
               "ScaleOut": {
                  "Port": "${RemotePort}",
                  "Hosts": "${Hosts}",
                  "ConcurrentExecution": "${FSConcurrentExecution}"
               },
               "RepeatCount": "${TestRepeatCount}",
               "Description": "4K Block, Log Volume 5GB, Overwrite",
               "Hint": "Log",
               "InputVector": {
                  "BlockSize": 4096,
                  "DirectoryName": "${LogVolume}",
                  "FileOverwrite": true,
                  "FileSize": 5368709120,
                  "RandomAccess": false,
                  "RandomData": true,
                  "AsyncReadSubmit": "${LogAsyncReadSubmit}",
                  "AsyncWriteSubmitActive": "${LogAsyncWriteSubmitActive}",
                  "AsyncWriteSubmitBlocks": "${LogAsyncWriteSubmitBlocks}",
                  "ExtMaxParallelIoRequests": "${LogExtMaxParallelIoRequests}",
                  "ExtMaxSubmitBatchSize": "${LogExtMaxSubmitBatchSize}",
                  "ExtMinSubmitBatchSize": "${LogExtMinSubmitBatchSize}",
                  "ExtNumCompletionQueues": "${LogExtNumCompletionQueues}",
                  "ExtNumSubmitQueues": "${LogExtNumSubmitQueues}",
                  "ExtSizeKernelIoQueue": "${ExtSizeKernelIoQueue}"
               }
            },
…
....


== Übersicht über den Prozess zur Storage-Größenbemessung

Die Anzahl der Festplatten pro HANA Host und die Host-Dichte für jedes Storage-Modell von SAP HANA wurden mithilfe des Test-Tools ermittelt.

Der Dimensionierungsprozess erfordert Einzelheiten, z. B. die Anzahl der SAP HANA-Hosts in der Produktion und für die Produktion nichtproduktive Umgebung, die RAM-Größe jedes Hosts und die Backup-Aufbewahrung der Storage-basierten Snapshot Kopien. Die Anzahl der SAP HANA-Hosts bestimmt den Storage Controller und die Anzahl der benötigten Festplatten.

Die Größe des RAM, die Netto-Datengröße auf der Festplatte jedes SAP HANA-Hosts und der Aufbewahrungszeitraum für das Snapshot-Backup werden als Inputs bei der Kapazitätsdimensionierung verwendet.

Die folgende Abbildung fasst den Dimensionierungsprozess zusammen.

image:saphana_aff_fc_image8.jpg["Die Abbildung zeigt den Input/Output-Dialog oder die Darstellung des schriftlichen Inhalts"]
